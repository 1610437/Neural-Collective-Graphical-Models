{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tqdm\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorboardX\n",
    "\n",
    "import model\n",
    "import datas\n",
    "import dataloader\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Select data which you use\n",
    "    is_sample = 2\n",
    "    #Hyper parameter for objective function\n",
    "    lam=10.0\n",
    "    #Dimention of input layer and hidden layer\n",
    "    input_layer=5\n",
    "    hidden_layer=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_sample==1:\n",
    "    population_data, location, adj_table = datas.read_sample()\n",
    "elif is_sample==2:\n",
    "    population_data, location_table, adj_table, z_tensor = datas.read_chofu()\n",
    "    location = [[row[0] / 6 - 0.5, row[1] / 6 - 0.5] for row in location_table]\n",
    "else:\n",
    "    population_data, adj_table, location_table, neighbor_table = datas.read_data(Path(\"datas/chohu\"), \"chohu_01.csv\", False)\n",
    "    location = [[row[0] / 11 - 0.5, row[1] / 14 - 0.5] for row in location_table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 374.97it/s]\n"
     ]
    }
   ],
   "source": [
    "time_size = torch.tensor(population_data).shape[0]\n",
    "location_size = torch.tensor(population_data).shape[1]\n",
    "z_tensor=torch.zeros(time_size-1,location_size,location_size,dtype=torch.double)\n",
    "for l in tqdm.trange(time_size-1):\n",
    "    for ll in range(location_size):\n",
    "        #z_tensor[l,ll,:]=torch.tensor([0.8],dtype=torch.double).pow(z_table[ll,:])*torch.tensor(population_data[l]).sum()\n",
    "        #z_tensor[l,ll,:]=z_table[ll,:]*torch.tensor(population_data[l]).sum()/adj_table[ll,:].sum()/5#weight1\n",
    "        #weight2,3傾斜なしと傾斜あり\n",
    "        z_tensor[l,ll,:]=adj_table[ll,]*torch.tensor(population_data[l])[ll]*0.2\n",
    "        z_tensor[l,ll,ll]=torch.tensor(population_data[l])[ll]*adj_table[ll,ll]*0.8\n",
    "        #z_tensor[l,ll,:]=adj_table[ll,:]*model.digit#noweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#Use cuda\n",
    "use_cuda = True\n",
    "available_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if (use_cuda and available_cuda) else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set default type of tensor\n",
    "torch.set_default_dtype(torch.double)\n",
    "#torch.set_grad_enabled(True)\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use tensorboardX\n",
    "board = tensorboardX.SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCGM(\n",
       "  (fc1): Linear(in_features=5, out_features=40, bias=True)\n",
       "  (fc2): Linear(in_features=40, out_features=1, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantinate model\n",
    "mod = model.NCGM(input_layer, hidden_layer,z_tensor)\n",
    "mod.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantinate objective function\n",
    "objective = model.NCGM_objective(location_size,adj_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantinate optimizer\n",
    "#optimizer = optim.SGD(mod.parameters(), lr=0.5)\n",
    "optimizer = optim.Adam(mod.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 443.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#Instantinate dataloader\n",
    "data_loader = dataloader.Data_loader(population_data, location, time_size, location_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "mod.train()\n",
    "itr = tqdm.trange(2000)\n",
    "#itr = tqdm.trange(1)\n",
    "losses = []\n",
    "ave_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:40<00:00,  7.14it/s, loss=9.37]  \n"
     ]
    }
   ],
   "source": [
    "for i in itr:\n",
    "    for t in range(time_size - 1):\n",
    "    #for t in range(1):\n",
    "        input_data, yt, yt1 = data_loader.get_t_input(t)\n",
    "        theta = mod(input_data)\n",
    "        loss = objective(theta, mod.Z[t], yt, yt1, lam)\n",
    "        #print(loss)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #itr.set_postfix(ordered_dict=OrderedDict(loss=loss.item(), b_grad=mod.fc2.bias.grad))\n",
    "        itr.set_postfix(ordered_dict=OrderedDict(loss=loss.item()))\n",
    "\n",
    "        board.add_scalar(\"loss\", loss.item(), i * (time_size - 1) + t)\n",
    "        ave_loss = ave_loss + loss.item()\n",
    "            \n",
    "    board.add_text(\"Z\", str(mod.Z), i)\n",
    "    board.add_scalar(\"ave_loss\", ave_loss / (time_size - 1), i)\n",
    "    ave_loss = 0.0\n",
    "\n",
    "    #with open(\"output/{0:05}.txt\".format(i), 'wt') as f:\n",
    "        #  f.write(str(mod.Z.data.numpy()))\n",
    "    \n",
    "#tensorboard用の値のjsonファイルへの保存[ポイント6]\n",
    "board.export_scalars_to_json(\"./all_scalars.json\")\n",
    "board.add_text(\"progress\", \"finish\", 0)\n",
    "#SummaryWriterのclose[ポイント7]\n",
    "board.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('outputcsv/z11_25l.csv', 'w')\n",
    "writer = csv.writer(f, lineterminator='\\n')\n",
    "for l in range(time_size-1):\n",
    "#for l in range(1):\n",
    "    for ll in range(location_size):\n",
    "        writer.writerow(mod.Z[l,ll,:].detach().numpy()*model.digit)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('outputcsv/theta11_25l.csv', 'w')\n",
    "writer = csv.writer(f, lineterminator='\\n')\n",
    "for l in range(location_size):\n",
    "    writer.writerow(theta[l,:].detach().numpy())\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
